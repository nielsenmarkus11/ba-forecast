---
title: "Austrailian Wines Forecast"
output: html_document
---

```{r, message=F}
library(forecast)
```


## Data Prep
Read in the data and choose the first time series for the analysis.

```{r}
dat <- read.csv('AustralianWines.csv', colClasses=c("character",rep("numeric",6)),na.strings="*")

dat.ts <- ts(dat[,-1],start=c(1980,1),frequency=12)

plot(dat.ts[,1])

```

Split the data into training and validation series and do roll-forward validation.
```{r}
k <- 60 
n <- length(dat.ts[,1])
forecast.mae <- matrix(NA,n-k,2)
train.mae <- matrix(NA,n-k,60)
st <- tsp(dat.ts[,1])[1]+(k-2)/12
 
for(i in 1:(n-k))
{
  xshort <- window(dat.ts[,1], start=st+(i-59)/12, end=st + i/12)
  xnext <- window(dat.ts[,1], start=st + (i+1)/12, end=st + (i+2)/12)
  fit1 <- snaive(xshort,2)
  fcast1 <- fit1$mean
  forecast.mae[i,1:length(xnext)] <- abs(fit1[['mean']]-xnext)
  train.mae[i,1:length(xshort)] <-abs(fit1[['residuals']])
}
 
boxplot(cbind(train.mae,forecast.mae),col=c(rep("blue",60),rep("red",2)),
        main="Evaluation of the Distribution of Absolute Error\nby Time Period", xlab="Time Stamp", ylab="Absolute Error")
legend("topleft",legend=c("Training","Forecast"),col=c("blue","red"),lty=1,lwd=10)
```

## Results of Validation
The distribution of the errors for the forecasts are not that different from the distributions of errors in the training data. The model appears to not have been overfit.
